# Training


By convention, the printed training loss is always the average loss of previous
steps while the validation loss is the loss for the current step(a single step).
So it's reasonable that the training loss will be greater than validation loss
at the begining stage of training.
